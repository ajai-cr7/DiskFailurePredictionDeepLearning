{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "API SWOGUT Samplling Algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajai-cr7/DiskFailurePredictionDeepLearning/blob/main/API_SWOGUT_Samplling_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Ax-lMgJSja"
      },
      "source": [
        "# Example of getting neighbors for an instance\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "class swogut:\n",
        "  N=100\n",
        "  K=5\n",
        "  C=1\n",
        "  M=100\n",
        "  MinoritySample = []\n",
        "  MajoritySample = []\n",
        "  New_MinoritySample = []\n",
        "  New_MajoritySample = []\n",
        "  SyntheticSample = []\n",
        "  RemovedMajoritySample = []\n",
        "  T = 0\n",
        "  centroids = []\n",
        "  df_head = []\n",
        "\n",
        "  def __init__(self,N,K,C,M,Minority_class,Majority_class,df_head):\n",
        "    self.N=N\n",
        "    self.K=min(K,len(Minority_class)-1) \n",
        "    self.MinoritySample = Minority_class\n",
        "    self.MajoritySample = Majority_class\n",
        "    self.New_MajoritySample = Majority_class\n",
        "    self.New_MinoritySample = [i for i in Minority_class]\n",
        "    self.T=len(self.MinoritySample)\n",
        "    self.df_head = df_head\n",
        "    self.C=min(C,len(Minority_class)-1) \n",
        "    self.M=min(M,len(Majority_class)-1) \n",
        "\n",
        "\n",
        "  def getMajorityData(self):\n",
        "    return self.New_MajoritySample\n",
        "\n",
        "  def getMinorityData(self):\n",
        "    return self.New_MinoritySample\n",
        "\n",
        "  def Plot_Syntheticdata(self,X,Y,COL):\n",
        "    df = pd.DataFrame(self.SyntheticSample,columns=self.df_head)    \n",
        "    df.plot(kind = 'scatter',x = X,y = Y,color=COL)\n",
        "\n",
        "  def Plot_RemovedData(self,X,Y,COL):\n",
        "    df = pd.DataFrame(self.RemovedMajoritySample,columns=self.df_head)    \n",
        "    df.plot(kind = 'scatter',x = X,y = Y,color=COL)\n",
        "  \n",
        "  def Plot_Centroids(self,X,Y,COL):\n",
        "    df = pd.DataFrame(self.centroids,columns=self.df_head)    \n",
        "    df.plot(kind = 'scatter',x = X,y = Y,color=COL)\n",
        "\n",
        "  def Plot_MajoritySample(self,X,Y,COL):\n",
        "    df = pd.DataFrame(self.MajoritySample,columns=self.df_head)    \n",
        "    df.plot(kind = 'scatter',x = X,y = Y,color=COL)\n",
        "\n",
        "  def Plot_MinoritySample(self,X,Y,COL):\n",
        "    df = pd.DataFrame(self.MinoritySample,columns=self.df_head)    \n",
        "    df.plot(kind = 'scatter',x = X,y = Y,color=COL)\n",
        "\n",
        "  def Plot_InitialDataset(self,X,Y,COL1,COL2):\n",
        "    dx = pd.DataFrame(self.MajoritySample,columns=self.df_head)\n",
        "    dy = pd.DataFrame(self.MinoritySample,columns=self.df_head)\n",
        "    ax = dx.plot(kind = 'scatter', x = X,y = Y,color = COL1)\n",
        "    dy.plot(kind = 'scatter', x = X,y = Y,color = COL2,ax=ax)\n",
        "\n",
        "  def Plot_FinalDataset(self,X,Y,COL1,COL2):\n",
        "    dx = pd.DataFrame(self.New_MajoritySample,columns=self.df_head)\n",
        "    dy = pd.DataFrame(self.New_MinoritySample,columns=self.df_head)\n",
        "    ax = dx.plot(kind = 'scatter', x = X,y = Y,color = COL1)\n",
        "    dy.plot(kind = 'scatter', x = X,y = Y,color = COL2,ax=ax)\n",
        "\n",
        "  def multiply_ratio(self,row1, ratio):\n",
        "    row2 = [n*ratio for n in row1]\n",
        "    return row2\n",
        "\n",
        "  def add_weight(self,row1, weight,nn):\n",
        "\n",
        "    res_list = []\n",
        "    for i in range(0, len(row1)):\n",
        "      if row1[i] - nn[i] >0:\n",
        "        res_list.append(row1[i] - weight[i])\n",
        "      else:\n",
        "        res_list.append(row1[i] + weight[i])\n",
        "    return res_list\n",
        "\n",
        "  def euclidean_distance_row(self,row1, row2):\n",
        "    row3 =[]\n",
        "    for i in range(len(row1)):\n",
        "      row3.append(abs(row1[i] - row2[i]))\n",
        "    return row3\n",
        "  # calculate the Euclidean distance between two vectors\n",
        "  def euclidean_distance(self,row1, row2):\n",
        "    distance = 0.0\n",
        "    for i in range(len(row1)-1):\n",
        "      distance += abs(row1[i] - row2[i])\n",
        "    return distance\n",
        "  \n",
        "  # Locate the most similar neighbors\n",
        "  def get_neighbors(self,train, test_row, num_neighbors):\n",
        "    distances = list()\n",
        "    for train_row in train: \n",
        "      dist = self.euclidean_distance(test_row, train_row)\n",
        "      distances.append((train_row, dist))\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "    neighbors = list()\n",
        "    for i in range(1,num_neighbors+1):\n",
        "      neighbors.append(distances[i][0])\n",
        "    return neighbors\n",
        "\n",
        "  def get_neighbors1(self,train, test_row, num_neighbors):\n",
        "    distances = list()\n",
        "    for train_row in train: \n",
        "      dist = self.euclidean_distance(test_row, train_row)\n",
        "      distances.append((train_row, dist))\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "    neighbors = list()\n",
        "    for i in range(num_neighbors):\n",
        "      neighbors.append(distances[i][0])\n",
        "    return neighbors\n",
        "\n",
        "\n",
        "\n",
        "    # Locate the most similar neighbors\n",
        "  def get_neighbors_distance(self,train, test_row, num_neighbors):\n",
        "    distances = list()\n",
        "    for train_row in train:\n",
        "      dist = self.euclidean_distance(test_row, train_row)\n",
        "      distances.append((train_row, dist))\n",
        "    distances.sort(key=lambda tup: tup[1])\n",
        "    distance =0.0\n",
        "    for i in range(1,num_neighbors+1):\n",
        "      distance += distances[i][1]\n",
        "    return distance\n",
        "\n",
        "  def sample(self):\n",
        "    \n",
        "    \n",
        "    centroid = [0 for n in self.MinoritySample[0]]\n",
        "    for i in range(len(self.MinoritySample)):\n",
        "      for x in range(len(self.MinoritySample[0])):\n",
        "        centroid[x] +=self.MinoritySample[i][x]\n",
        "  \n",
        "    for x in range(len(centroid)):\n",
        "        centroid[x] = centroid[x]/len(self.MinoritySample)\n",
        "\n",
        "    if self.N<100:\n",
        "      self.T=int((self.N/100)*self.T)\n",
        "      self.N=100\n",
        "    \n",
        "    self.N=int(self.N/100)\n",
        "    \n",
        "    \n",
        "    for i in range(0,self.T):\n",
        "      times = self.N\n",
        "      x = self.get_neighbors(self.MinoritySample, self.MinoritySample[i], self.K)\n",
        "      \n",
        "      while(times>0):\n",
        "        ran = random.randint(0,min(len(x)-1,(self.K-1)))\n",
        "        nn = [n for n in x[ran]]\n",
        "        \n",
        "        sdis = self.euclidean_distance_row(self.MinoritySample[i],nn)\n",
        "      \n",
        "        di= self.get_neighbors_distance(self.MinoritySample, self.MinoritySample[i], self.K)\n",
        "        dnn = self.get_neighbors_distance(self.MinoritySample, nn, self.K)\n",
        "        mdis1 = 0\n",
        "        mdis2 = 0\n",
        "\n",
        "        for i1 in range(len(centroid)):\n",
        "          mdis1 += abs(centroid[i1] - self.MinoritySample[i][i1])\n",
        "\n",
        "        for i1 in range(len(centroid)):\n",
        "          mdis2 += abs(centroid[i1] - nn[i1])\n",
        "\n",
        "\n",
        "        ratio =0 \n",
        "        try:\n",
        "          ratio = di+mdis1/ (di + dnn + mdis1 + mdis2)\n",
        "        except:\n",
        "          ratio = 0\n",
        "\n",
        "      \n",
        "        \n",
        "\n",
        "        sdis = self.multiply_ratio(sdis,ratio)\n",
        "        sdata = self.add_weight(self.MinoritySample[i],sdis,nn)\n",
        "        self.SyntheticSample.append(sdata)\n",
        "        self.New_MinoritySample.append(sdata)\n",
        "        times=times-1\n",
        "\n",
        "    self.centroids = []\n",
        "    \n",
        "   \n",
        "    \n",
        "    self.centroids.append(centroid);\n",
        "    l = len(self.MinoritySample)-1\n",
        "    while  self.C>1:\n",
        "      self.C = self.C-1\n",
        "      centroids_temp = self.get_neighbors1(self.MinoritySample, centroid,len(self.MinoritySample))\n",
        "      self.centroids.append(centroids_temp[l])\n",
        "      l=l-1\n",
        "      centroid = centroids_temp[l]\n",
        "      \n",
        "\n",
        "  \n",
        "\n",
        "    for i in range(len(self.centroids)):\n",
        "      list_remove = self.get_neighbors1(self.MajoritySample, self.centroids[i],min(len(self.MinoritySample),self.M))\n",
        "      for t in list_remove:\n",
        "        self.RemovedMajoritySample.append(t)\n",
        "        self.New_MajoritySample.remove(t)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "      \n",
        "      \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkzR1l48xgDP",
        "outputId": "f83ac0df-cab8-404e-ba69-4930430ef58d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Us2eBUjS4dd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb8ch8tMWDUu"
      },
      "source": [
        "For Actual dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf88QFClS4jg"
      },
      "source": [
        "import numpy as np # used for handling numbers\n",
        "import pandas as pd # used for handling the dataset\n",
        "from sklearn.impute import SimpleImputer # used for handling missing data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
        "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
        "from sklearn.preprocessing import StandardScaler # used for feature scaling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sMmexvN1NcX"
      },
      "source": [
        "Add path to dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHqGwY82S4m5"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "path = r'PATH TO DATASET FOLDER'\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "df = pd.concat(map(pd.read_csv, all_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fOeceCkXhJ_"
      },
      "source": [
        "df = df.drop(['model','date', 'serial_number','capacity_bytes'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeD9ocIAaGil"
      },
      "source": [
        "for i in df:\n",
        "  if \"raw\" in i:\n",
        "    df = df.drop([i],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmLI8ivWXhNf"
      },
      "source": [
        "df = df.dropna(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBDlQ5sbX0rI"
      },
      "source": [
        "for col in df.columns:\n",
        "    if len(df[col].unique()) == 1:\n",
        "        df.drop(col,inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arw-BE6jb5Iv"
      },
      "source": [
        "dataset = df.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLt0Ost7b5LN"
      },
      "source": [
        "Majority_class = []\n",
        "Minority_class = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy5-sdt8b5Nj"
      },
      "source": [
        "for i in dataset:\n",
        "  if i[0] == 1:\n",
        "    Minority_class.append(i)\n",
        "  else:\n",
        "    Majority_class.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw5f5_wOb5Qz",
        "outputId": "51e19ecc-4539-4b5d-87d5-507d75e6c57b"
      },
      "source": [
        "print(len(Majority_class))\n",
        "print(len(Minority_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113828\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otuddE4eyAxB"
      },
      "source": [
        "Actual Algorithm where you have to tune the parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcuTvjAmdNyK",
        "outputId": "6b373ba0-ac4e-4aa8-e45d-44131a3da58f"
      },
      "source": [
        "\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "# define dataset\n",
        "\n",
        "\n",
        "print(\"Before Sampling\")\n",
        "print(\"Majority Class : \" + str(len(Majority_class)))\n",
        "print(\"Minority Class : \" + str(len(Minority_class)))\n",
        "\n",
        "sw = swogut(3000,30,300,60,Minority_class,Majority_class,list(df))\n",
        "sw.sample()\n",
        "print(\"After Sampling\")\n",
        "\n",
        "print(\"Majority Class : \" + str(len(sw.getMajorityData())))\n",
        "print(\"Minority Class : \" + str(len(sw.getMinorityData())))\n",
        "Majority_class = sw.getMajorityData()\n",
        "Minority_class = sw.getMinorityData()\n",
        "\n",
        "x1 = []\n",
        "y1 =[]\n",
        "for i in Majority_class:\n",
        "  n = i[1:]\n",
        "  x1.append(n)\n",
        "  y1.append(i[0])\n",
        "\n",
        "for i in Minority_class:\n",
        "  n = i[1:]\n",
        "  x1.append(n)\n",
        "  y1.append(i[0])\n",
        " \n",
        "X = np.array(x1)\n",
        "y = np.array(y1) \n",
        "# define model\n",
        "model = DecisionTreeClassifier()\n",
        "# evaluate pipeline\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Sampling\n",
            "Majority Class : 113828\n",
            "Minority Class : 5\n",
            "After Sampling\n",
            "Majority Class : 113808\n",
            "Minority Class : 155\n",
            "Mean ROC AUC: 0.983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOLv97jXp9DH"
      },
      "source": [
        "Majority_class.extend(Minority_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxvR9SEpP_8O"
      },
      "source": [
        "df1 = pd.DataFrame(Majority_class,columns =list(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIzC-fMm13wU"
      },
      "source": [
        "Add path to Sampled dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX6NSb1BoxjG"
      },
      "source": [
        "import time\n",
        "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "  \n",
        "df1.to_csv(r'PATH TO SAMPLED DATASET FOLDER'+timestr+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCfDC5YtshvL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}