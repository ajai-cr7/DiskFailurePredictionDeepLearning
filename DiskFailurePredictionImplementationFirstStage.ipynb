{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiskFailurePredictionImplementationFirstStage.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajai-cr7/DiskFailurePredictionDeepLearning/blob/main/DiskFailurePredictionImplementationFirstStage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RYAtx1GV08b"
      },
      "source": [
        "# Load Packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oZQ9GkZe9cK",
        "outputId": "6b4f9315-19b7-439d-d6b2-73f665b8f5be"
      },
      "source": [
        "# import necessary modules\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# load the data set\n",
        "data = pd.read_csv('./2014-10-23.csv')\n",
        "\n",
        "# print info about columns in the dataframe\n",
        "print(data.info())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38592 entries, 0 to 38591\n",
            "Data columns (total 85 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   date                  38592 non-null  object \n",
            " 1   serial_number         38592 non-null  object \n",
            " 2   model                 38592 non-null  object \n",
            " 3   capacity_bytes        38592 non-null  int64  \n",
            " 4   failure               38592 non-null  int64  \n",
            " 5   smart_1_normalized    38592 non-null  int64  \n",
            " 6   smart_1_raw           38592 non-null  int64  \n",
            " 7   smart_2_normalized    22335 non-null  float64\n",
            " 8   smart_2_raw           22335 non-null  float64\n",
            " 9   smart_3_normalized    38592 non-null  int64  \n",
            " 10  smart_3_raw           38592 non-null  int64  \n",
            " 11  smart_4_normalized    38592 non-null  int64  \n",
            " 12  smart_4_raw           38592 non-null  int64  \n",
            " 13  smart_5_normalized    38592 non-null  int64  \n",
            " 14  smart_5_raw           38592 non-null  int64  \n",
            " 15  smart_7_normalized    38592 non-null  int64  \n",
            " 16  smart_7_raw           38592 non-null  int64  \n",
            " 17  smart_8_normalized    22338 non-null  float64\n",
            " 18  smart_8_raw           22338 non-null  float64\n",
            " 19  smart_9_normalized    38592 non-null  int64  \n",
            " 20  smart_9_raw           38592 non-null  int64  \n",
            " 21  smart_10_normalized   38592 non-null  int64  \n",
            " 22  smart_10_raw          38592 non-null  int64  \n",
            " 23  smart_11_normalized   1838 non-null   float64\n",
            " 24  smart_11_raw          1838 non-null   float64\n",
            " 25  smart_12_normalized   38592 non-null  int64  \n",
            " 26  smart_12_raw          38592 non-null  int64  \n",
            " 27  smart_13_normalized   3 non-null      float64\n",
            " 28  smart_13_raw          3 non-null      float64\n",
            " 29  smart_15_normalized   0 non-null      float64\n",
            " 30  smart_15_raw          0 non-null      float64\n",
            " 31  smart_183_normalized  14040 non-null  float64\n",
            " 32  smart_183_raw         14040 non-null  float64\n",
            " 33  smart_184_normalized  14577 non-null  float64\n",
            " 34  smart_184_raw         14577 non-null  float64\n",
            " 35  smart_187_normalized  14577 non-null  float64\n",
            " 36  smart_187_raw         14577 non-null  float64\n",
            " 37  smart_188_normalized  14577 non-null  float64\n",
            " 38  smart_188_raw         14577 non-null  float64\n",
            " 39  smart_189_normalized  14573 non-null  float64\n",
            " 40  smart_189_raw         14573 non-null  float64\n",
            " 41  smart_190_normalized  14578 non-null  float64\n",
            " 42  smart_190_raw         14578 non-null  float64\n",
            " 43  smart_191_normalized  12682 non-null  float64\n",
            " 44  smart_191_raw         12682 non-null  float64\n",
            " 45  smart_192_normalized  36392 non-null  float64\n",
            " 46  smart_192_raw         36392 non-null  float64\n",
            " 47  smart_193_normalized  36238 non-null  float64\n",
            " 48  smart_193_raw         36238 non-null  float64\n",
            " 49  smart_194_normalized  38591 non-null  float64\n",
            " 50  smart_194_raw         38591 non-null  float64\n",
            " 51  smart_195_normalized  3021 non-null   float64\n",
            " 52  smart_195_raw         3021 non-null   float64\n",
            " 53  smart_196_normalized  24019 non-null  float64\n",
            " 54  smart_196_raw         24019 non-null  float64\n",
            " 55  smart_197_normalized  38592 non-null  int64  \n",
            " 56  smart_197_raw         38592 non-null  int64  \n",
            " 57  smart_198_normalized  38592 non-null  int64  \n",
            " 58  smart_198_raw         38592 non-null  int64  \n",
            " 59  smart_199_normalized  38592 non-null  int64  \n",
            " 60  smart_199_raw         38592 non-null  int64  \n",
            " 61  smart_200_normalized  1838 non-null   float64\n",
            " 62  smart_200_raw         1838 non-null   float64\n",
            " 63  smart_201_normalized  3 non-null      float64\n",
            " 64  smart_201_raw         3 non-null      float64\n",
            " 65  smart_223_normalized  154 non-null    float64\n",
            " 66  smart_223_raw         154 non-null    float64\n",
            " 67  smart_225_normalized  154 non-null    float64\n",
            " 68  smart_225_raw         154 non-null    float64\n",
            " 69  smart_240_normalized  14530 non-null  float64\n",
            " 70  smart_240_raw         14530 non-null  float64\n",
            " 71  smart_241_normalized  14508 non-null  float64\n",
            " 72  smart_241_raw         14508 non-null  float64\n",
            " 73  smart_242_normalized  14508 non-null  float64\n",
            " 74  smart_242_raw         14508 non-null  float64\n",
            " 75  smart_250_normalized  94 non-null     float64\n",
            " 76  smart_250_raw         94 non-null     float64\n",
            " 77  smart_251_normalized  94 non-null     float64\n",
            " 78  smart_251_raw         94 non-null     float64\n",
            " 79  smart_252_normalized  94 non-null     float64\n",
            " 80  smart_252_raw         94 non-null     float64\n",
            " 81  smart_254_normalized  205 non-null    float64\n",
            " 82  smart_254_raw         205 non-null    float64\n",
            " 83  smart_255_normalized  0 non-null      float64\n",
            " 84  smart_255_raw         0 non-null      float64\n",
            "dtypes: float64(58), int64(24), object(3)\n",
            "memory usage: 25.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGPlQqiqfO_e",
        "outputId": "07396452-81d5-47b3-b0c2-5380f9db8505"
      },
      "source": [
        "data = data.drop(['serial_number','model','capacity_bytes'], axis = 1)\n",
        "\n",
        "data['failure'].value_counts()\n",
        "print(data.info())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38592 entries, 0 to 38591\n",
            "Data columns (total 82 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   date                  38592 non-null  object \n",
            " 1   failure               38592 non-null  int64  \n",
            " 2   smart_1_normalized    38592 non-null  int64  \n",
            " 3   smart_1_raw           38592 non-null  int64  \n",
            " 4   smart_2_normalized    22335 non-null  float64\n",
            " 5   smart_2_raw           22335 non-null  float64\n",
            " 6   smart_3_normalized    38592 non-null  int64  \n",
            " 7   smart_3_raw           38592 non-null  int64  \n",
            " 8   smart_4_normalized    38592 non-null  int64  \n",
            " 9   smart_4_raw           38592 non-null  int64  \n",
            " 10  smart_5_normalized    38592 non-null  int64  \n",
            " 11  smart_5_raw           38592 non-null  int64  \n",
            " 12  smart_7_normalized    38592 non-null  int64  \n",
            " 13  smart_7_raw           38592 non-null  int64  \n",
            " 14  smart_8_normalized    22338 non-null  float64\n",
            " 15  smart_8_raw           22338 non-null  float64\n",
            " 16  smart_9_normalized    38592 non-null  int64  \n",
            " 17  smart_9_raw           38592 non-null  int64  \n",
            " 18  smart_10_normalized   38592 non-null  int64  \n",
            " 19  smart_10_raw          38592 non-null  int64  \n",
            " 20  smart_11_normalized   1838 non-null   float64\n",
            " 21  smart_11_raw          1838 non-null   float64\n",
            " 22  smart_12_normalized   38592 non-null  int64  \n",
            " 23  smart_12_raw          38592 non-null  int64  \n",
            " 24  smart_13_normalized   3 non-null      float64\n",
            " 25  smart_13_raw          3 non-null      float64\n",
            " 26  smart_15_normalized   0 non-null      float64\n",
            " 27  smart_15_raw          0 non-null      float64\n",
            " 28  smart_183_normalized  14040 non-null  float64\n",
            " 29  smart_183_raw         14040 non-null  float64\n",
            " 30  smart_184_normalized  14577 non-null  float64\n",
            " 31  smart_184_raw         14577 non-null  float64\n",
            " 32  smart_187_normalized  14577 non-null  float64\n",
            " 33  smart_187_raw         14577 non-null  float64\n",
            " 34  smart_188_normalized  14577 non-null  float64\n",
            " 35  smart_188_raw         14577 non-null  float64\n",
            " 36  smart_189_normalized  14573 non-null  float64\n",
            " 37  smart_189_raw         14573 non-null  float64\n",
            " 38  smart_190_normalized  14578 non-null  float64\n",
            " 39  smart_190_raw         14578 non-null  float64\n",
            " 40  smart_191_normalized  12682 non-null  float64\n",
            " 41  smart_191_raw         12682 non-null  float64\n",
            " 42  smart_192_normalized  36392 non-null  float64\n",
            " 43  smart_192_raw         36392 non-null  float64\n",
            " 44  smart_193_normalized  36238 non-null  float64\n",
            " 45  smart_193_raw         36238 non-null  float64\n",
            " 46  smart_194_normalized  38591 non-null  float64\n",
            " 47  smart_194_raw         38591 non-null  float64\n",
            " 48  smart_195_normalized  3021 non-null   float64\n",
            " 49  smart_195_raw         3021 non-null   float64\n",
            " 50  smart_196_normalized  24019 non-null  float64\n",
            " 51  smart_196_raw         24019 non-null  float64\n",
            " 52  smart_197_normalized  38592 non-null  int64  \n",
            " 53  smart_197_raw         38592 non-null  int64  \n",
            " 54  smart_198_normalized  38592 non-null  int64  \n",
            " 55  smart_198_raw         38592 non-null  int64  \n",
            " 56  smart_199_normalized  38592 non-null  int64  \n",
            " 57  smart_199_raw         38592 non-null  int64  \n",
            " 58  smart_200_normalized  1838 non-null   float64\n",
            " 59  smart_200_raw         1838 non-null   float64\n",
            " 60  smart_201_normalized  3 non-null      float64\n",
            " 61  smart_201_raw         3 non-null      float64\n",
            " 62  smart_223_normalized  154 non-null    float64\n",
            " 63  smart_223_raw         154 non-null    float64\n",
            " 64  smart_225_normalized  154 non-null    float64\n",
            " 65  smart_225_raw         154 non-null    float64\n",
            " 66  smart_240_normalized  14530 non-null  float64\n",
            " 67  smart_240_raw         14530 non-null  float64\n",
            " 68  smart_241_normalized  14508 non-null  float64\n",
            " 69  smart_241_raw         14508 non-null  float64\n",
            " 70  smart_242_normalized  14508 non-null  float64\n",
            " 71  smart_242_raw         14508 non-null  float64\n",
            " 72  smart_250_normalized  94 non-null     float64\n",
            " 73  smart_250_raw         94 non-null     float64\n",
            " 74  smart_251_normalized  94 non-null     float64\n",
            " 75  smart_251_raw         94 non-null     float64\n",
            " 76  smart_252_normalized  94 non-null     float64\n",
            " 77  smart_252_raw         94 non-null     float64\n",
            " 78  smart_254_normalized  205 non-null    float64\n",
            " 79  smart_254_raw         205 non-null    float64\n",
            " 80  smart_255_normalized  0 non-null      float64\n",
            " 81  smart_255_raw         0 non-null      float64\n",
            "dtypes: float64(58), int64(23), object(1)\n",
            "memory usage: 24.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDr8zNUdfVGh",
        "outputId": "8fd9c968-571b-4157-ba8b-5330bac2b440"
      },
      "source": [
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "# data = data[[\"failure\",\"smart_1_normalized\",\"smart_2_normalized\",\"smart_3_normalized\",\"smart_4_normalized\"]]\n",
        "\n",
        "#take first 100000 rows with 5 column attributes\n",
        "data = data.loc[1:38000, [\"smart_1_normalized\",\"smart_3_normalized\",\"smart_4_normalized\",\"smart_5_normalized\",\"failure\",\"date\"]]\n",
        "\n",
        "#change float to int\n",
        "data[\"smart_1_normalized\"] = data[\"smart_1_normalized\"].fillna(0.0).astype(int)\n",
        "data[\"smart_3_normalized\"] = data[\"smart_3_normalized\"].fillna(0.0).astype(int)\n",
        "data[\"smart_4_normalized\"] = data[\"smart_4_normalized\"].fillna(0.0).astype(int)\n",
        "data[\"smart_5_normalized\"] = data[\"smart_5_normalized\"].fillna(0.0).astype(int)\n",
        "\n",
        "print(data)\n",
        "\n",
        "#print how many nan values present \n",
        "# print(data[\"failure\"].isnull().sum())\n",
        "\n",
        "#display how much data is failure or success\n",
        "data['failure'].value_counts()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       smart_1_normalized  smart_3_normalized  ...  failure        date\n",
            "1                     100                 127  ...        0  2014-10-23\n",
            "2                     100                 124  ...        0  2014-10-23\n",
            "3                     100                 137  ...        0  2014-10-23\n",
            "4                     200                 195  ...        0  2014-10-23\n",
            "5                     100                 131  ...        0  2014-10-23\n",
            "...                   ...                 ...  ...      ...         ...\n",
            "37996                 118                  97  ...        0  2014-10-23\n",
            "37997                 100                 124  ...        0  2014-10-23\n",
            "37998                 100                 126  ...        0  2014-10-23\n",
            "37999                 100                 100  ...        0  2014-10-23\n",
            "38000                 105                  94  ...        0  2014-10-23\n",
            "\n",
            "[38000 rows x 6 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    37992\n",
              "1        8\n",
              "Name: failure, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUWHIniXfXrq"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEqCiiu7Yu7j"
      },
      "source": [
        "\n",
        "def grid_tune_isolationforest():\n",
        "    iso = IsolationForest(random_state=0)\n",
        "    # Number of trees in random forest\n",
        "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n",
        "    # The number of samples to draw from X to train each base estimator.\n",
        "    max_samples = [0.2, 0.5, 0.8, 1]\n",
        "    # the proportion of outliers in the data set\n",
        "    contamination = ['auto', 0.1, 0.2, 0.3]\n",
        "    # The number of features to draw from X to train each base estimator.\n",
        "    max_features = [0.2, 0.5, 0.8, 1]\n",
        "    # Method of selecting samples for training each tree\n",
        "    bootstrap = [True, False]\n",
        "\n",
        "    \n",
        "    random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'bootstrap': bootstrap,\n",
        "               'max_samples': max_samples,\n",
        "               'contamination': contamination\n",
        "                }\n",
        "    def acc(y_true, y_pred): \n",
        "        y_pred = [0 if x > 0 else 1 for x in y_pred]\n",
        "        return accuracy_score(y_true, y_pred)\n",
        "    def f1(y_true, y_pred): \n",
        "        y_pred = [0 if x > 0 else 1 for x in y_pred]\n",
        "        return f1_score(y_true, y_pred)\n",
        "    iso_grid = GridSearchCV(\n",
        "        estimator = iso, \n",
        "        param_grid = random_grid, \n",
        "        cv = 3, \n",
        "        verbose=3, \n",
        "        n_jobs = -1, \n",
        "        scoring = {'f1': make_scorer(f1), 'acc': make_scorer(acc)}, \n",
        "        refit=\"f1\",\n",
        "        return_train_score=True\n",
        "    )\n",
        "    \n",
        "    return iso_grid"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ8uk80yWM7u"
      },
      "source": [
        "\n",
        "# Reading data from a combined file with both good and failed drives\n",
        "def split_train_val_test_data():\n",
        "    \n",
        "    df = data\n",
        "    print(df)\n",
        "\n",
        "    resample_data = True\n",
        "    smote_data = False\n",
        "\n",
        "    df_good = df.loc[df['failure'] == 0]\n",
        "    df_bad = df.loc[df['failure'] == 1]\n",
        "     \n",
        "    df_good = df_good.sort_values([\"date\"])\n",
        "    df_bad = df_bad.sort_values([\"date\"])\n",
        "\n",
        "    good_y = df_good[\"failure\"]\n",
        "    bad_y = df_bad[\"failure\"]\n",
        "\n",
        "    # Split into train (80%) and test (20%)\n",
        "    X_train_good, X_test_good, y_train_good, y_test_good = train_test_split(\n",
        "        df_good, good_y, train_size=0.8, shuffle=False)\n",
        "    X_train_bad, X_test_bad, y_train_bad, y_test_bad = train_test_split(\n",
        "        df_bad, bad_y, train_size=0.8, shuffle=False)\n",
        "\n",
        "\n",
        "    # Split train into train and validation\n",
        "    # Train(60%), Val(20%), Test(20%)\n",
        "#     X_train_good, X_val_good, y_train_good, y_val_good = train_test_split(\n",
        "#         X_train_good, y_train_good, train_size=0.75, shuffle=False)\n",
        "#     X_train_bad, X_val_bad, y_train_bad, y_val_bad = train_test_split(\n",
        "#         X_train_bad, y_train_bad, train_size=0.75, shuffle=False)\n",
        "        \n",
        "    if resample_data:\n",
        "        X_train_bad = resample(df_bad, replace=True, n_samples=len(X_train_good), random_state=1)\n",
        "        X_train_bad = X_train_bad.sort_values([\"date\"])\n",
        "\n",
        "    y_train_bad = X_train_bad[\"failure\"]\n",
        "\n",
        "    X_train = pd.concat([X_train_good, X_train_bad], axis=0)\n",
        "    y_train = pd.concat([y_train_good, y_train_bad], axis=0)\n",
        "#     X_val = pd.concat([X_val_good, X_val_bad], axis=0)\n",
        "#     y_val = pd.concat([y_val_good, y_val_bad], axis=0)\n",
        "    X_test = pd.concat([X_test_good, X_test_bad], axis=0)\n",
        "    y_test = pd.concat([y_test_good, y_test_bad], axis=0)\n",
        "\n",
        "    ignore_cols = [\"date\"] \n",
        "\n",
        "    X_train.drop(columns=ignore_cols, inplace=True, axis=1)\n",
        "    # X_val.drop(columns=\"date\", inplace=True, axis=1)\n",
        "    X_test.drop(columns=ignore_cols, inplace=True, axis=1)\n",
        "\n",
        "    if smote_data:\n",
        "        sm = SMOTE(random_state=42)\n",
        "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "    #return (X_train, X_val, X_test, y_train, y_val, y_test)\n",
        "    return (X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ho1SCXYw1A"
      },
      "source": [
        "def run(models, tune_model=False):\n",
        "    #X_train, X_val, X_test, y_train, y_val, y_test = split_train_val_test_data(drive_file = \"/ST12000NM0007_last_day_all_q_raw.csv\", smote_data=True)\n",
        "    X_train, X_test, y_train, y_test = split_train_val_test_data()\n",
        "    print(\"Data loaded successfully...\\n\")\n",
        "    for model in models:  \n",
        "        print(\"\\n\\n *\", type(model).__name__)  \n",
        "        \n",
        "        # if(type(model).__name__ == \"XGBClassifier\" and tune_model):\n",
        "        #     tune_xgb(model, X_train, y_train)\n",
        "\n",
        "        start = time()\n",
        "        model.fit(X_train, y_train)\n",
        "        end = time()\n",
        "        print(\"\\nTime to train:\", str((end - start)/60), \" mins\")\n",
        "        \n",
        "        print(\"Best Parameter\", model.best_params_)\n",
        "        # Test set results\n",
        "        print(\"\\n- Results on test set: \")\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred = y_pred = [0 if x > 0 else 1 for x in y_pred]\n",
        "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "        print(\"Scores:\\n\", classification_report(y_test, y_pred))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeV1N2cBYz81",
        "outputId": "7ab33d92-362d-4bdc-b1ee-c36903863189"
      },
      "source": [
        "# # load the data set\n",
        "# data = pd.read_csv('./2021-01-02.csv')\n",
        "\n",
        "# # print info about columns in the dataframe\n",
        "# print(data.info())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_list = []\n",
        "    iso = grid_tune_isolationforest()\n",
        "    print(iso)\n",
        "    models_list.append(iso)\n",
        "    run(models_list,tune_model=True)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=IsolationForest(behaviour='deprecated', bootstrap=False,\n",
            "                                       contamination='auto', max_features=1.0,\n",
            "                                       max_samples='auto', n_estimators=100,\n",
            "                                       n_jobs=None, random_state=0, verbose=0,\n",
            "                                       warm_start=False),\n",
            "             iid='deprecated', n_jobs=-1,\n",
            "             param_grid={'bootstrap': [True, False],\n",
            "                         'contamination': ['auto', 0.1, 0.2, 0.3],\n",
            "                         'max_features': [0.2, 0.5, 0.8, 1],\n",
            "                         'max_samples': [0.2, 0.5, 0.8, 1],\n",
            "                         'n_estimators': [100, 125, 150, 175, 200]},\n",
            "             pre_dispatch='2*n_jobs', refit='f1', return_train_score=True,\n",
            "             scoring={'acc': make_scorer(acc), 'f1': make_scorer(f1)},\n",
            "             verbose=3)\n",
            "       smart_1_normalized  smart_3_normalized  ...  failure        date\n",
            "1                     100                 127  ...        0  2014-10-23\n",
            "2                     100                 124  ...        0  2014-10-23\n",
            "3                     100                 137  ...        0  2014-10-23\n",
            "4                     200                 195  ...        0  2014-10-23\n",
            "5                     100                 131  ...        0  2014-10-23\n",
            "...                   ...                 ...  ...      ...         ...\n",
            "37996                 118                  97  ...        0  2014-10-23\n",
            "37997                 100                 124  ...        0  2014-10-23\n",
            "37998                 100                 126  ...        0  2014-10-23\n",
            "37999                 100                 100  ...        0  2014-10-23\n",
            "38000                 105                  94  ...        0  2014-10-23\n",
            "\n",
            "[38000 rows x 6 columns]\n",
            "Data loaded successfully...\n",
            "\n",
            "\n",
            "\n",
            " * GridSearchCV\n",
            "Fitting 3 folds for each of 640 candidates, totalling 1920 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   53.7s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 10.3min\n"
          ]
        }
      ]
    }
  ]
}